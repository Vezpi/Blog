---
slug: migration-opnsense-proxmox-highly-available
title: Migration vers mon cluster OPNsense hautement disponible dans Proxmox VE
description: La dÃ©marche dÃ©taillÃ©e de la migration de ma box OPNsense physique vers un cluster de VM hautement disponible dans Proxmox VE.
date: 2025-11-20
draft: false
tags:
  - opnsense
  - high-availability
  - proxmox
categories:
  - homelab
---
## Intro

C'est la derniÃ¨re Ã©tape de mon aventure de virtualisationÂ d'**OPNsense**.

Il y a quelques mois, ma [box OPNsense physique a crash]({{< ref "post/10-opnsense-crash-disk-panic" >}}) Ã  cause d'une dÃ©faillance matÃ©rielle. Cela a plongÃ© ma maison dans le noir, littÃ©ralement. Pas de rÃ©seau, pas de lumiÃ¨res.

ğŸ’¡ Pour Ã©viter de me retrouver Ã  nouveau dans cette situation, j'ai imaginÃ© un plan pour virtualiser mon pare-feu OPNsense dans mon clusterÂ **Proxmox VE**. La derniÃ¨re fois, j'avais mis en place un [proof of concept]({{< ref "post/12-opnsense-virtualization-highly-available" >}}) pour valider cette solution : crÃ©er un cluster de deux VMÂ **OPNsense**Â dans Proxmox et rendre le firewall hautement disponible.

Cette fois, je vais couvrir la crÃ©ation de mon futur cluster OPNsense depuis zÃ©ro, planifier la bascule et finalement migrer depuis ma box physique actuelle. C'est parti !

---
## La Configuration VLAN

Pour mes plans, je dois connecter le WAN, provenant de ma box FAI, Ã  mon switch principal. Pour cela je crÃ©e un VLAN dÃ©diÃ© pour transporter ce flux jusqu'Ã  mes nÅ“uds Proxmox.

### UniFi

D'abord, je configure mon rÃ©seau de couche 2 qui est gÃ©rÃ© par UniFi. LÃ , je dois crÃ©er deux VLANs :

- _WAN_Â (20) : transporte le WAN entre ma box FAI et mes nÅ“uds Proxmox.
- _pfSync_Â (44), communication entre mes nÅ“uds OPNsense.

Dans le contrÃ´leur UniFi, dansÂ `ParamÃ¨tres`Â >Â `RÃ©seaux`, j'ajoute unÂ `New Virtual Network`. Je le nommeÂ `WAN`Â et lui donne l'ID VLAN 20 :
![Creation of the WAN VLAN in the UniFi Controller](img/unifi-add-vlan-for-wan.png)

Je fais la mÃªme chose pour le VLANÂ `pfSync`Â avec l'ID VLAN 44.

Je prÃ©vois de brancher ma box FAI sur le port 15 de mon switch, qui est dÃ©sactivÃ© pour l'instant. Je l'active, dÃ©finis le VLAN natif sur le nouveauÂ `WAN (20)`Â et dÃ©sactive le trunking :
![Configuration du port du switch UniFi pour la liaison WAN](img/unifi-enable-port-wan-vlan.png)

Une fois ce rÃ©glage appliquÃ©, je m'assure que seules les ports oÃ¹ sont connectÃ©s mes nÅ“uds Proxmox propagent ces VLANs sur leur trunk.

J'ai fini la configuration UniFi.

### Proxmox SDN

Maintenant que le VLAN peut atteindre mes nÅ“uds, je veux le gÃ©rer dans le SDN de Proxmox. J'ai configurÃ© le SDN dans [cet article]({{< ref "post/11-proxmox-cluster-networking-sdn" >}}).

DansÂ `Datacenter`Â >Â `SDN`Â >Â `VNets`, je crÃ©e un nouveau VNet, je l'appelleÂ `vlan20`Â pour suivre ma propre convention de nommage, je lui donne l'aliasÂ _WAN_Â et j'utilise le tag (ID VLAN) 20 :
![Creation of the VNet for the WAN in the Proxmox SDN](img/proxmox-sdn-new-vnet-wan.png)

Je crÃ©e aussi leÂ `vlan44`Â pour le VLANÂ _pfSync_, puis j'applique cette configuration et nous avons terminÃ© avec le SDN.

---
## CrÃ©ation des VMs

Maintenant que la configuration VLAN est faite, je peux commencer Ã  construire les machines virtuelles sur Proxmox.

La premiÃ¨re VM s'appelleÂ `cerbere-head1`Â (je ne vous l'ai pas dit ? Mon firewall actuel s'appelleÂ `cerbere`, Ã§a a encore plus de sens maintenant !). Voici les rÃ©glages :
- **Type d'OS**Â : Linux (mÃªme si OPNsense est basÃ© sur FreeBSD)
- **Type de machine**Â :Â `q35`
- **BIOS**Â :Â `OVMF (UEFI)`
- **Disque**Â : 20 Go sur stockage Ceph distribuÃ©
- **RAM**Â : 4 Go, ballooning dÃ©sactivÃ©
- **CPU**Â : 2 vCPU
- **NICs**, pare-feu dÃ©sactivÃ© :
    1. `vmbr0`Â (_Mgmt_)
    2. `vlan20`Â (_WAN_)
    3. `vlan13`Â _(User)_
    4. `vlan37`Â _(IoT)_
    5. `vlan44`Â _(pfSync)_
    6. `vlan55`Â _(DMZ)_
    7. `vlan66`Â _(Lab)_

![Hardware settings of the OPNsense VM in Proxmox](img/proxmox-cerbere-vm-settings.png)

â„¹ï¸ Maintenant je clone cette VM pour crÃ©erÂ `cerbere-head2`, puis je procÃ¨de Ã  l'installation d'OPNsense. Je ne veux pas entrer trop dans les dÃ©tails de l'installation d'OPNsense, je l'ai dÃ©jÃ  documentÃ©e dans le [proof of concept]({{< ref "post/12-opnsense-virtualization-highly-available" >}}).

AprÃ¨s l'installation des deux instances OPNsense, j'attribue Ã  chacune leur IP sur le rÃ©seauÂ _Mgmt_Â :
- `cerbere-head1`Â :Â `192.168.88.2/24`
- `cerbere-head2`Â :Â `192.168.88.3/24`

Tant que ces routeurs ne gÃ¨rent pas encore les rÃ©seaux, je leur donne comme passerelle mon routeur OPNsense actuel (`192.168.88.1`) pour me permettre de les atteindre depuis mon portable dans un autre VLAN.

---
## Configuration d'OPNsense

Initialement, j'envisageais de restaurer ma configuration OPNsense existante et de l'adapter Ã  l'installation.

Puis j'ai dÃ©cidÃ© de repartir de zÃ©ro pour documenter et partager la procÃ©dure. Cette partie devenant trop longue, j'ai prÃ©fÃ©rÃ© crÃ©er un article dÃ©diÃ©.

ğŸ“– Vous pouvez trouver les dÃ©tails de la configuration complÃ¨te d'OPNsense dans cet [article]({{< ref "post/13-opnsense-full-configuration" >}}), couvrant HA, DNS, DHCP, VPN et reverse proxy.

---
## VM Proxmox Hautement Disponible

Les ressources (VM ou LXC) dans Proxmox VE peuvent Ãªtre marquÃ©es comme hautement disponibles, voyons comment les configurer.

### PrÃ©requis pour la HA Proxmox

D'abord, votre cluster Proxmox doit le permettre. Il y a quelques exigences :

- Au moins 3 nÅ“uds pour avoir le quorum
- Stockage partagÃ© pour vos ressources
- Horloge synchronisÃ©e
- RÃ©seau fiable

Un mÃ©canisme de fencing doit Ãªtre activÃ©. Le fencing est le processus d'isoler un nÅ“ud de cluster dÃ©faillant pour s'assurer qu'il n'accÃ¨de plus aux ressources partagÃ©es. Cela Ã©vite les situations de split-brain et permet Ã  Proxmox HA de redÃ©marrer en toute sÃ©curitÃ© les VM affectÃ©es sur des nÅ“uds sains. Par dÃ©faut, il utilise le watchdog logiciel Linux,Â _softdog_, suffisant pour moi.

Dans Proxmox VE 8, il Ã©tait possible de crÃ©er des groupes HA, en fonction de leurs ressources, emplacements, etc. Cela a Ã©tÃ© remplacÃ©, dans Proxmox VE 9, par des rÃ¨gles d'affinitÃ© HA. C'est la raison principale derriÃ¨re la mise Ã  niveau de mon cluster Proxmox VE, que j'ai dÃ©taillÃ©e dans ce [post]({{< ref "post/14-proxmox-cluster-upgrade-8-to-9-ceph" >}}).

### Configurer la HA pour les VM

Le cluster Proxmox est capable de fournir de la HA pour les ressources, mais vous devez dÃ©finir les rÃ¨gles.

DansÂ `Datacenter`Â >Â `HA`, vous pouvez voir le statut et gÃ©rer les ressources. Dans le panneauÂ `Resources`Â je clique surÂ `Add`. Je dois choisir la ressource Ã  configurer en HA dans la liste, iciÂ `cerbere-head1`Â avec l'ID 122. Puis dans l'infobulle je peux dÃ©finir le maximum de redÃ©marrages et de relocations, je laisseÂ `Failback`Â activÃ© et l'Ã©tat demandÃ© Ã Â `started`Â :
![Create HA resource in Proxmox](img/proxmox-add-vm-ha.png)

Le cluster Proxmox s'assurera maintenant que cette VM est dÃ©marrÃ©e. Je fais de mÃªme pour l'autre VM OPNsense,Â `cerbere-head2`.

### RÃ¨gles d'AffinitÃ© HA

Super, mais je ne veux pas qu'elles tournent sur le mÃªme nÅ“ud. C'est lÃ  qu'intervient la nouvelle fonctionnalitÃ© des rÃ¨gles d'affinitÃ© HA de Proxmox VE 9. Proxmox permet de crÃ©er des rÃ¨gles d'affinitÃ© de nÅ“ud et de ressource. Peu m'importe sur quel nÅ“ud elles tournent, mais je ne veux pas qu'elles soient ensemble. J'ai besoin d'une rÃ¨gle d'affinitÃ© de ressource.

DansÂ `Datacenter`Â >Â `HA`Â >Â `Affinity Rules`, j'ajoute une nouvelle rÃ¨gle d'affinitÃ© de ressource HA. Je sÃ©lectionne les deux VMs et choisis l'optionÂ `Keep Separate`Â :
![Create HA resource affinity in Proxmox](img/proxmox-ha-resource-affinity-rule.png)

âœ… Mes VMs OPNsense sont maintenant entiÃ¨rement prÃªtes !

---
## Migration

ğŸš€ Il est temps de rendre cela rÃ©el !

Je ne vais pas mentir, je suis assez excitÃ©. Je travaille pour ce moment depuis des jours.

### Le Plan de Migration

Ma box OPNsense physique est directement connectÃ©e Ã  ma box FAI. Je veux la remplacer par le cluster de VM. (Pour Ã©viter d'Ã©crire le mot OPNsense Ã  chaque ligne, j'appellerai simplement l'ancienne instance "la box" et la nouvelle "la VM" )

Voici le plan :
1. Sauvegarde de la configuration de la box.
2. DÃ©sactiver le serveur DHCP sur la box.
3. Changer les adresses IP de la box.
4. Changer les VIP sur la VM.
5. DÃ©sactiver la passerelle sur la VM.
6. Configurer le DHCP sur les deux VMs.
7. Activer le rÃ©pÃ©teur mDNS sur la VM.
8. RÃ©pliquer les services sur la VM.
9. DÃ©placement du cÃ¢ble Ethernet.

### StratÃ©gie de Retour ArriÃ¨re

Aucune. ğŸ˜

Je plaisante, le retour arriÃ¨re consiste Ã  restaurer la configuration de la box, arrÃªter les VMs OPNsense et rebrancher le cÃ¢ble Ethernet dans la box.

### Plan de vÃ©rification

Pour valider la migration, je dresse une checklist :
1. Bail DHCP WAN dans la VM.
2. Ping depuis mon PC vers le VIP du VLAN User.
3. Ping entre les VLANs.
4. SSH vers mes machines.
5. Renouveler le bail DHCP.
6. VÃ©rifierÂ `ipconfig`
7. Tester l'accÃ¨s Ã  des sites internet.
8. VÃ©rifier les logs du pare-feu.
9. VÃ©rifier mes services web.
10. VÃ©rifier que mes services internes ne sont pas accessibles depuis l'extÃ©rieur.
11. Tester le VPN.
12. VÃ©rifier tous les appareils IoT.
13. VÃ©rifier les fonctionnalitÃ©s Home Assistant.
14. VÃ©rifier que la TV fonctionne.
15. Tester le Chromecast.
16. Imprimer quelque chose.
17. VÃ©rifier la blocklist DNS.
18. Speedtest.
19. Bascule.
20. Failover.
21. Reprise aprÃ¨s sinistre.
22. Champagne !

Est-ce que Ã§a va marcher ? On verra bien !

### Ã‰tapes de Migration

1. **Sauvegarde de la configuration de la box.**

Sur mon instance OPNsense physique, dansÂ `System` > `Configuration` > `Backups`, je clique sur le boutonÂ `Download configuration`Â qui me donne le prÃ©cieux fichier XML. Celui qui m'a sauvÃ© la mise la [derniÃ¨re fois]({{< ref "post/10-opnsense-crash-disk-panic" >}}).

2. **DÃ©sactiver le serveur DHCP sur la box.**

DansÂ `Services`Â >Â `ISC DHCPv4`, et pour toutes mes interfaces, je dÃ©sactive le serveur DHCP. Je ne fournis que du DHCPv4 dans mon rÃ©seau.

3. **Changer les adresses IP de la box.**

DansÂ `Interfaces`, et pour toutes mes interfaces, je modifie l'IP du firewall, deÂ `.1`Â Ã Â `.253`. Je veux rÃ©utiliser la mÃªme adresse IP comme VIP, et garder cette instance encore joignable si besoin.

DÃ¨s que je clique surÂ `Apply`, je perds la communication, ce qui est attendu.

4. **Changer les VIP sur la VM.**

Sur ma VM maÃ®tre, dansÂ `Interfaces`Â >Â `Virtual IPs`Â >Â `Settings`, je change l'adresse VIP pour chaque interface et la mets enÂ `.1`.

5. **DÃ©sactiver la passerelle sur la VM.**

DansÂ `System`Â >Â `Gateways`Â >Â `Configuration`, je dÃ©sactiveÂ `LAN_GW`Â qui n'est plus nÃ©cessaire.

6. **Configurer le DHCP sur les deux VMs.**

Sur les deux VMs, dansÂ `Services`Â >Â `Dnsmasq DNS & DHCP`, j'active le service sur mes 5 interfaces.

7. **Activer le rÃ©pÃ©teur mDNS sur la VM.**

DansÂ `Services`Â >Â `mDNS Repeater`, j'active le service et j'active aussi leÂ `CARP Failover`.

Le service ne dÃ©marre pas. Je verrai ce problÃ¨me plus tard.

8. **RÃ©pliquer les services sur la VM.**

DansÂ `SystÃ¨me`Â >Â `High Availability`Â >Â `Status`, je clique sur le boutonÂ `Synchronize and reconfigure all`.

9. **DÃ©placement du cÃ¢ble Ethernet.**

Physiquement dans mon rack, je dÃ©branche le cÃ¢ble Ethernet du port WAN (`igc0`) de ma box OPNsense physique et je le branche sur le port 15 de mon switch UniFi.

---
## VÃ©rification

ğŸ˜®â€ğŸ’¨ Je prends une grande inspiration et commence la phase de vÃ©rification.

### Checklist

- âœ… Bail DHCP WAN dans la VM.
- âœ… Ping depuis mon PC vers le VIP du VLAN User.
- âš ï¸ Ping entre VLANs.  
    Les pings fonctionnent, mais j'observe quelques pertes, environ 10 %.
- âœ… SSH vers mes machines.
- âœ… Renouvellement du bail DHCP.
- âœ… VÃ©rifierÂ `ipconfig`
- âŒ Tester un site internet. â†’ âœ…  
Quelques sites fonctionnent, tout est incroyablement lent... Ã‡a doit Ãªtre le DNS. J'essaie de rÃ©soudre un domaine au hasard, Ã§a marche. Mais je ne peux pas rÃ©soudre `google.com`. Je redÃ©marre le service Unbound DNS, tout fonctionne maintenant. C'est toujours le DNS...
- âš ï¸ VÃ©rifier les logs du pare-feu.  
Quelques flux sont bloquÃ©s, pas critique.
- âœ… VÃ©rifier mes services web.
- âœ… VÃ©rifier que mes services internes ne sont pas accessibles depuis l'extÃ©rieur.
- âœ… Tester le VPN.
- âœ… VÃ©rifier tous les appareils IoT.
- âœ… VÃ©rifier les fonctionnalitÃ©s Home Assistant.
- âœ… VÃ©rifier que la TV fonctionne.
- âŒ Tester le Chromecast.  
C'est liÃ© au service mDNS qui ne parvient pas Ã  dÃ©marrer. Je peux le dÃ©marrer si je dÃ©coche l'optionÂ `CARP Failover`. Le Chromecast est visible maintenant. â†’ âš ï¸
- âœ… Imprimer quelque chose.
- âœ… VÃ©rifier la blocklist DNS.
- âœ… Speedtest.  
J'observe environ 15 % de diminution de bande passante (de 940Mbps Ã  825Mbps).
- âŒ Bascule.  
La bascule fonctionne difficilement, beaucoup de paquets perdus pendant la bascule. Le service rendu n'est pas gÃ©nial : plus d'accÃ¨s internet et mes services web sont inaccessibles.
- âŒ› Failover.
- âŒ› Reprise aprÃ¨s sinistre.  
Ã€ tester plus tard.

ğŸ“ Bon, les rÃ©sultats sont plutÃ´t bons, pas parfaits, mais satisfaisants !
### RÃ©solution des ProblÃ¨mes

Je me concentre sur la rÃ©solution des problÃ¨mes restants rencontrÃ©s lors des tests.

1. **DNS**

Lors de la bascule, la connexion internet ne fonctionne pas. Pas de DNS, c'est toujours le DNS.

C'est parce que le nÅ“ud de secours n'a pas de passerelle lorsqu'il est en mode passif. L'absence de passerelle empÃªche le DNS de rÃ©soudre. AprÃ¨s la bascule, il conserve des domaines non rÃ©solus dans son cache. Ce problÃ¨me conduit aussi Ã  un autre souci : quand il est passif, je ne peux pas mettre Ã  jour le systÃ¨me.

**Solution** : DÃ©finir une passerelle sur l'interfaceÂ _Mgmt_Â pointant vers l'autre nÅ“ud, avec un numÃ©ro de prioritÃ© plus Ã©levÃ© que la passerelle WAN (un numÃ©ro plus Ã©levÃ© signifie une prioritÃ© plus basse). Ainsi, cette passerelle n'est pas active tant que le nÅ“ud est maÃ®tre.

2. **Reverse Proxy**

Lors de la bascule, tous les services web que j'hÃ©berge (reverse proxy/proxy couche 4) renvoient cette erreur :Â `SSL_ERROR_INTERNAL_ERROR_ALERT`. AprÃ¨s vÃ©rification des services synchronisÃ©s via XMLRPC Sync, Caddy et mDNS repeater n'Ã©taient pas sÃ©lectionnÃ©s. C'est parce que ces services ont Ã©tÃ© installÃ©s aprÃ¨s la configuration initiale du HA.

**Solution** : Ajouter Caddy Ã  XMLRPC Sync.

3. **Pertes de paquets**

J'observe environ 10 % de pertes de paquets pour les pings depuis n'importe quel VLAN vers le VLANÂ _Mgmt_. Je n'ai pas ce problÃ¨me pour les autres VLANs.

Le VLANÂ _Mgmt_Â est le VLAN natif dans mon rÃ©seau, cela pourrait Ãªtre la raison de ce problÃ¨me. C'est le seul rÃ©seau non dÃ©fini dans le SDN Proxmox. Je ne veux pas avoir Ã  tagger ce VLAN.

**Solution** : DÃ©sactiver le pare-feu Proxmox de cette interface pour la VM. En rÃ©alitÃ©, je les ai tous dÃ©sactivÃ©s et mis Ã  jour la documentation ci-dessus. Je ne sais pas exactement pourquoi cela causait ce type de problÃ¨me, mais la dÃ©sactivation a rÃ©solu mon souci (j'ai pu reproduire le comportement en rÃ©activant le pare-feu).

4. **Script CARP**

Lors de la bascule, le script d'Ã©vÃ©nement CARP est dÃ©clenchÃ© autant de fois qu'il y a d'interfaces. J'ai 5 IPs virtuelles, le script reconfigure mon interface WAN 5 fois.

**Solution** : Retravailler le script pour rÃ©cupÃ©rer l'Ã©tat de l'interface WAN et ne reconfigurer l'interface que lorsque c'est nÃ©cessaire :
```php
#!/usr/local/bin/php
<?php
/**
 * OPNsense CARP event script
 * - Enables/disables the WAN interface only when needed
 * - Avoids reapplying config when CARP triggers multiple times
 */

require_once("config.inc");
require_once("interfaces.inc");
require_once("util.inc");
require_once("system.inc");

// Read CARP event arguments
$subsystem = !empty($argv[1]) ? $argv[1] : '';
$type = !empty($argv[2]) ? $argv[2] : '';

// Accept only MASTER/BACKUP events
if (!in_array($type, ['MASTER', 'BACKUP'])) {
    // Ignore CARP INIT, DEMOTED, etc.
    exit(0);
}

// Validate subsystem name format, expected pattern: <ifname>@<vhid>
if (!preg_match('/^[a-z0-9_]+@\S+$/i', $subsystem)) {
    log_error("Malformed subsystem argument: '{$subsystem}'.");
    exit(0);
}

// Interface key to manage
$ifkey = 'wan';
// Determine whether WAN interface is currently enabled
$ifkey_enabled = !empty($config['interfaces'][$ifkey]['enable']) ? true : false;

// MASTER event
if ($type === "MASTER") {
    // Enable WAN only if it's currently disabled
    if (!$ifkey_enabled) {
        log_msg("CARP event: switching to '$type', enabling interface '$ifkey'.", LOG_WARNING);
        $config['interfaces'][$ifkey]['enable'] = '1';
        write_config("enable interface '$ifkey' due CARP event '$type'", false);
        interface_configure(false, $ifkey, false, false);
    } else {
        log_msg("CARP event: already '$type' for interface '$ifkey', nothing to do.");
    }

// BACKUP event
} else {
    // Disable WAN only if it's currently enabled
    if ($ifkey_enabled) {
        log_msg("CARP event: switching to '$type', disabling interface '$ifkey'.", LOG_WARNING);
        unset($config['interfaces'][$ifkey]['enable']);
        write_config("disable interface '$ifkey' due CARP event '$type'", false);
        interface_configure(false, $ifkey, false, false);
    } else {
        log_msg("CARP event: already '$type' for interface '$ifkey', nothing to do.");
    }
}
```

5. **mDNS Repeater**

Le rÃ©pÃ©teur mDNS ne veut pas dÃ©marrer quand je sÃ©lectionne l'optionÂ `CARP Failover`.

**Solution** : La machine nÃ©cessite un redÃ©marrage pour dÃ©marrer ce service compatible CARP.

6. **Adresse IPv6**

Mon nÅ“udÂ `cerbere-head1`Â crie dans le fichier de logs tandis que l'autre ne le fait pas. Voici les messages affichÃ©s chaque seconde quand il est maÃ®tre :
```plaintext
Warning rtsold <interface_up> vtnet1 is disabled. in the logs (OPNsense)
```

Un autre message que j'ai plusieurs fois aprÃ¨s un switchback :
```plaintext
Error dhcp6c transmit failed: Can't assign requested address
```

Ceci est liÃ© Ã  IPv6. J'observe que mon nÅ“ud principal n'a pas d'adresse IPv6 globale, seulement une link-local. De plus, il n'a pas de passerelle IPv6. Mon nÅ“ud secondaire, en revanche, a Ã  la fois l'adresse globale et la passerelle.

Je ne suis pas expert IPv6, aprÃ¨s quelques heures de recherche, j'abandonne IPv6. Si quelqu'un peut m'aider, ce serait vraiment apprÃ©ciÃ© !

**Contournement** : Supprimer DHCPv6 pour mon interface WAN.

### Confirmation

Maintenant que tout est corrigÃ©, je peux Ã©valuer les performances du failover.

1. **Basculement**

En entrant manuellement en mode maintenance CARP depuis l'interface WebGUI, aucune perte de paquets n'est observÃ©e. Impressionnant.

2. **Failover**

Pour simuler un failover, je tue la VM OPNsense active. Ici j'observe une seule perte de paquet. GÃ©nial.

![Ping test during OPNsense CARP failover](img/opnsense-ping-failover.png)

3. **Reprise aprÃ¨s sinistre**

Une reprise aprÃ¨s sinistre est ce qui se produirait aprÃ¨s un arrÃªt complet d'un cluster Proxmox, suite Ã  une coupure de courant par exemple. Je n'ai pas eu le temps (ni le courage) de m'en occuper, je prÃ©fÃ¨re mieux me prÃ©parer pour Ã©viter les dommages collatÃ©raux. Mais il est certain que ce genre de scÃ©nario doit Ãªtre Ã©valuÃ©.

#### Avantages SupplÃ©mentaires

Outre le fait que cette nouvelle configuration est plus rÃ©siliente, j'ai constatÃ© quelques autres avantages.

Mon rack est minuscule et l'espace est restreint. L'ensemble chauffe beaucoup, dÃ©passant les 40 Â°C au sommet du rack en Ã©tÃ©. RÃ©duire le nombre de machines allumÃ©es a permis de faire baisser la tempÃ©rature. J'ai gagnÃ© 1,5 Â°C aprÃ¨s avoir Ã©teint l'ancien boÃ®tier OPNsense, c'est super !

La consommation Ã©lectrique est Ã©galement un point important, mon petit datacenter consommait en moyenne 85 W. LÃ  encore, j'ai constatÃ© une lÃ©gÃ¨re baisse, d'environ 8 W. Sachant que le systÃ¨me fonctionne 24/7, ce n'est pas nÃ©gligeable.

Enfin, j'ai Ã©galement retirÃ© le boÃ®tier lui-mÃªme et le cÃ¢ble d'alimentation. Les places sont trÃ¨s limitÃ©es, ce qui est un autre point positif.

---
## Conclusion

ğŸ‰ J'ai rÃ©ussi les gars ! Je suis trÃ¨s fier du rÃ©sultat, et fier de moi.

De mon [premier crash de ma box OPNsense]({{< ref "post/10-opnsense-crash-disk-panic" >}}), Ã  la recherche d'une solution, en passant par la [proof of concept]({{< ref "post/12-opnsense-virtualization-highly-available" >}}) de haute disponibilitÃ©, jusqu'Ã  cette migration, ce fut un projet assez long, mais extrÃªmement intÃ©ressant.

ğŸ¯ Se fixer des objectifs, c'est bien, mais les atteindre, c'est encore mieux.

Je vais maintenant mettre OPNsense de cÃ´tÃ© un petit moment pour me recentrer sur mon apprentissage de Kubernetes !

Comme toujours, si vous avez des questions, des remarques ou une solution Ã  mon problÃ¨me d'IPv6, je serai ravi de vous aider.