---
slug: opnsense-virtualization-highly-available
title: Construire un Cluster OPNsense Hautement Disponible sur Proxmox VE
description: Une preuve de concept montrant comment virtualiser OPNsense sur Proxmox VE, configurer la haute disponibilit√© avec CARP et pfSync, et g√©rer une seule IP WAN.
date: 2025-09-29
draft: false
tags:
  - opnsense
  - proxmox
  - high-availability
categories:
  - homelab
---
## Intro

J‚Äôai r√©cemment rencontr√© mon premier vrai probl√®me, ma box **OPNsense** physique a plant√© √† cause d‚Äôun _kernel panic_. J‚Äôai d√©taill√© ce qu'il s'est pass√© dans [cet article]({{< ref "post/10-opnsense-crash-disk-panic" >}}).

Cette panne m‚Äôa fait repenser mon installation. Un seul pare-feu est un point de d√©faillance unique, donc pour am√©liorer la r√©silience j‚Äôai d√©cid√© de prendre une nouvelle approche : **virtualiser OPNsense**.

√âvidemment, faire tourner une seule VM ne suffirait pas. Pour obtenir une vraie redondance, il me faut deux instances OPNsense en **Haute Disponibilit√©**, l‚Äôune active et l‚Äôautre en attente.

Avant de d√©ployer √ßa sur mon r√©seau, j‚Äôai voulu valider l‚Äôid√©e dans mon homelab. Dans cet article, je vais d√©tailler la preuve de concept : d√©ployer deux VM OPNsense dans un cluster **Proxmox VE** et les configurer pour fournir un pare-feu hautement disponible.

---
## Infrastructure Actuelle

Au sommet de mon installation, mon modem FAI, une _Freebox_ en mode bridge, reli√© directement √† l‚Äôinterface `igc0` de ma box OPNsense, servant d‚Äôinterface **WAN**. Sur `igc1`, le **LAN** est connect√© √† mon switch principal via un port trunk, avec le VLAN 1 comme VLAN natif pour mon r√©seau de management.

Ce switch relie √©galement mes trois n≈ìuds Proxmox, chacun sur un port trunk avec le m√™me VLAN natif. Chaque n≈ìud dispose de deux cartes r√©seau : une pour le trafic g√©n√©ral, et l‚Äôautre d√©di√©e au r√©seau de stockage Ceph, connect√© √† un switch s√©par√© de 2,5 Gbps.

Depuis le crash d‚ÄôOPNsense, j‚Äôai simplifi√© l‚Äôarchitecture en supprimant le lien LACP, qui n‚Äôapportait pas de r√©elle valeur :
![Current homelab network diagram](img/homelan-current-physical-layout.png)

Jusqu‚Äô√† r√©cemment, le r√©seau Proxmox de mon cluster √©tait tr√®s basique : chaque n≈ìud √©tait configur√© individuellement sans v√©ritable logique commune. Cela a chang√© apr√®s la d√©couverte du SDN Proxmox, qui m‚Äôa permis de centraliser les d√©finitions de VLAN sur l‚Äôensemble du cluster. J‚Äôai d√©crit cette √©tape dans [cet article]({{< ref "post/11-proxmox-cluster-networking-sdn" >}}).

---
## Preuve de Concept

Place au lab. Voici les √©tapes principales :
1. Ajouter quelques VLANs dans mon homelab
2. Cr√©er un faux routeur FAI
3. Construire deux VMs OPNsense
4. Configurer la haute disponibilit√©
5. Tester la bascule

![Diagram of the POC for OPNsense high availability](img/poc-opnsense-diagram.png)

### Ajouter des VLANs dans mon homelab

Pour cette exp√©rimentation, je cr√©e trois nouveaux VLANs :
- **VLAN 101** : _POC WAN_
- **VLAN 102** : _POC LAN_
- **VLAN 103** : _POC pfSync_

Dans l‚Äôinterface Proxmox, je vais dans `Datacenter` > `SDN` > `VNets` et je clique sur `Create` :
![Create POC VLANs in the Proxmox SDN](img/proxmox-sdn-create-poc-vlans.png)

Une fois les trois VLANs cr√©√©s, j‚Äôapplique la configuration.

J‚Äôajoute ensuite ces trois VLANs dans mon contr√¥leur UniFi. Ici, seul l‚ÄôID et le nom sont n√©cessaires, le contr√¥leur se charge de les propager via les trunks connect√©s √† mes n≈ìuds Proxmox VE.

### Cr√©er une VM ‚ÄúFausse Box FAI‚Äù

Pour simuler mon modem FAI actuel, j‚Äôai cr√©√© une VM appel√©e `fake-freebox`. Cette VM route le trafic entre les r√©seaux _POC WAN_ et _Lab_, et fait tourner un serveur DHCP qui ne d√©livre qu‚Äôun seul bail, exactement comme ma vraie Freebox en mode bridge.

Cette VM dispose de 2 cartes r√©seau, que je configure avec Netplan :
- `eth0` (_POC WAN_ VLAN 101) : adresse IP statique `10.101.0.254/24`
- `enp6s19` (Lab VLAN 66) : adresse IP obtenue en DHCP depuis mon routeur OPNsense actuel, en amont
```yaml
network:
  version: 2
  ethernets:
    eth0:
      addresses:
        - 10.101.0.254/24
    enp6s19:
      dhcp4: true
```

J‚Äôactive ensuite le routage IP pour permettre √† cette VM de router le trafic :
```bash
echo "net.ipv4.ip_forward=1" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```

Puis je configure du masquage (NAT) afin que les paquets sortant via le r√©seau Lab ne soient pas rejet√©s par mon OPNsense actuel :
```bash
sudo iptables -t nat -A POSTROUTING -o enp6s19 -j MASQUERADE
sudo apt install iptables-persistent -y
sudo netfilter-persistent save
```

J‚Äôinstalle `dnsmasq` comme serveur DHCP l√©ger :
```bash
sudo apt install dnsmasq -y
```

Dans `/etc/dnsmasq.conf`, je configure un bail unique (`10.101.0.150`) et je pointe le DNS vers mon OPNsense actuel, sur le VLAN _Lab_ :
```
interface=eth0
bind-interfaces
dhcp-range=10.101.0.150,10.101.0.150,255.255.255.0,12h
dhcp-option=3,10.101.0.254      # default gateway = this VM
dhcp-option=6,192.168.66.1      # DNS server  
```

Je red√©marre le service `dnsmasq` pour appliquer la configuration :
```bash
sudo systemctl restart dnsmasq
```

La VM `fake-freebox` est maintenant pr√™te √† fournir du DHCP sur le VLAN 101, avec un seul bail disponible.

### Construire les VMs OPNsense

Je commence par t√©l√©charger l‚ÄôISO d‚ÄôOPNsense et je l‚Äôupload sur un de mes n≈ìuds Proxmox :  
![Upload de l‚ÄôISO OPNsense dans Proxmox](img/proxmox-upload-opnsense-iso.png)

#### Cr√©ation de la VM

Je cr√©e la premi√®re VM `poc-opnsense-1` avec les param√®tres suivants :
- Type d‚ÄôOS : Linux (m√™me si OPNsense est bas√© sur FreeBSD)
- Type de machine : `q35`
- BIOS : `OVMF (UEFI)`, stockage EFI sur mon pool Ceph
- Disque : 20 Gio sur Ceph
- CPU/RAM : 2 vCPU, 2 Gio de RAM
- Cartes r√©seau :
    1. VLAN 101 (_POC WAN_)
    2. VLAN 102 (_POC LAN_)
    3. VLAN 103 (_POC pfSync_)
![OPNsense VM settings in Proxmox](img/proxmox-create-poc-vm-opnsense.png)

‚ÑπÔ∏è Avant de la d√©marrer, je clone cette VM pour pr√©parer la seconde : `poc-opnsense-2`

Au premier d√©marrage, je tombe sur une erreur ‚Äúaccess denied‚Äù. Pour corriger, j‚Äôentre dans le BIOS, **Device Manager > Secure Boot Configuration**, je d√©coche _Attempt Secure Boot_ et je red√©marre :  
![Disable Secure Boot in Proxmox BIOS](img/proxmox-disable-secure-boot-option.png)

#### Installation d‚ÄôOPNsense

La VM d√©marre sur l‚ÄôISO, je ne touche √† rien jusqu‚Äô√† l‚Äô√©cran de login :  
![OPNsense CLI login screen in LiveCD](img/opnsense-vm-installation-welcome.png)

Je me connecte avec `installer` / `opnsense` et je lance l‚Äôinstallateur. Je s√©lectionne le disque QEMU de 20 Go comme destination et je d√©marre l‚Äôinstallation :  
![Barre de progression de l‚Äôinstallation OPNsense](img/opnsense-vm-installation-progress-bar.png)

Une fois termin√©, je retire l‚ÄôISO du lecteur et je red√©marre la machine.

#### Configuration de Base d‚ÄôOPNsense

Au red√©marrage, je me connecte avec `root` / `opnsense` et j‚Äôarrive au menu CLI :  
![Menu CLI apr√®s une installation fra√Æche d‚ÄôOPNsense](img/opnsense-vm-installation-cli-menu.png)

Avec l‚Äôoption 1, je r√©assigne les interfaces :  
![Configuration des interfaces dans OPNsense via le CLI](img/opnsense-vm-installation-assign-interfaces.png)

L‚Äôinterface WAN r√©cup√®re bien `10.101.0.150/24` depuis la `fake-freebox`. Je configure le LAN sur `10.102.0.2/24` et j‚Äôajoute un pool DHCP de `10.102.0.10` √† `10.102.0.99` :  
![Interface WAN OPNsense recevant une IP depuis la VM `fake-freebox`](img/opnsense-vm-installation-interfaces-configured.png)

‚úÖ La premi√®re VM est pr√™te, je reproduis l‚Äôop√©ration pour la seconde OPNsense `poc-opnsense-2`, qui aura l‚ÄôIP `10.102.0.3`.

### Configurer OPNsense en Haute Disponibilit√©

Avec les deux VMs OPNsense op√©rationnelles, il est temps de passer √† la configuration via le WebGUI. Pour y acc√©der, j‚Äôai connect√© une VM Windows au VLAN _POC LAN_ et ouvert l‚ÄôIP de l‚ÄôOPNsense sur le port 443 :  
![OPNsense WebGUI depuis une VM Windows](img/opnsense-vm-webgui-from-poc-lan.png)

#### Ajouter l‚ÄôInterface pfSync

La troisi√®me carte r√©seau (`vtnet2`) est assign√©e √† l‚Äôinterface _pfSync_. Ce r√©seau d√©di√© permet aux deux firewalls de synchroniser leurs √©tats via le VLAN _POC pfSync_ :  
![Add pfSync interface in OPNsense](img/opnsense-vm-assign-pfsync-interface.png)

J‚Äôactive l‚Äôinterface sur chaque instance et je leur attribue une IP statique :
- **poc-opnsense-1** : `10.103.0.2/24`
- **poc-opnsense-2** : `10.103.0.3/24`

Puis, j‚Äôajoute une r√®gle firewall sur chaque n≈ìud pour autoriser tout le trafic provenant de ce r√©seau sur l‚Äôinterface _pfSync_ :  
![Create new firewall rule on pfSync interface to allow any traffic in that network](img/opnsense-vm-firewall-allow-pfsync.png)

#### Configurer la Haute Disponibilit√©

Direction `System` > `High Availability` > `Settings`.
- Sur le master (`poc-opnsense-1`), je configure les `General Settings` et les `Synchronization Settings`.
- Sur le backup (`poc-opnsense-2`), seuls les `General Settings` suffisent (on ne veut pas qu‚Äôil √©crase la config du master).  
![OPNsense High Availability settings](img/opnsense-vm-high-availability-settings.png)

Une fois appliqu√©, je v√©rifie la synchro dans l‚Äôonglet `Status` :  
![OPNsense High Availability status](img/opnsense-vm-high-availability-status.png)

#### Cr√©er une IP Virtuelle

Pour fournir une passerelle partag√©e aux clients, je cr√©e une IP virtuelle (VIP) en **CARP** (Common Address Redundancy Protocol) sur l‚Äôinterface LAN. L‚ÄôIP est port√©e par le n≈ìud actif et bascule automatiquement en cas de failover.

Menu : `Interfaces` > `Virtual IPs` > `Settings` :  
![Create CARP virtual IP in OPNsense](img/opnsense-vm-create-vip-carp.png)

Je r√©plique ensuite la config depuis `System > High Availability > Status` avec le bouton `Synchronize and reconfigure all`.

Sur `Interfaces > Virtual IPs > Status`, le master affiche la VIP en `MASTER` et le backup en `BACKUP`.

#### Reconfigurer le DHCP

Pour la HA, il faut adapter le DHCP. Comme **Dnsmasq** ne supporte pas la synchro des baux, chaque instance doit r√©pondre ind√©pendamment.

Sur le master :
- `Services` > `Dnsmasq DNS & DHCP` > `General` : cocher `Disable HA sync`
- `DHCP ranges` : cocher aussi `Disable HA sync`
- `DHCP options` : ajouter l‚Äôoption `router [3]` avec la valeur `10.102.0.1` (VIP LAN)
- `DHCP options` : cloner la r√®gle pour `dns-server [6]` vers la m√™me VIP.  
![Edit DHCP options for Dnsmasq in OPNsense](img/opnsense-vm-dnsmasq-add-option.png)

Sur le backup :
- `Services` > `Dnsmasq DNS & DHCP` > `General` : cocher `Disable HA sync`
- R√©gler `DHCP reply delay` √† `5` secondes (laisser la priorit√© au master)
- `DHCP ranges` : d√©finir un autre pool, plus petit (`10.102.0.200 -> 220`).

Ainsi, seules les **options** DHCP sont synchronis√©es, les plages restant distinctes.

#### Interface WAN

Mon modem FAI n‚Äôattribue qu‚Äôune seule IP en DHCP, je ne veux pas que mes 2 VMs entrent en comp√©tition. Pour g√©rer √ßa :
1. Dans Proxmox, je copie l‚Äôadresse MAC de `net0` (WAN) de `poc-opnsense-1` et je l‚Äôapplique √† `poc-opnsense-2`. Ainsi, le bail DHCP est partag√©.  
‚ö†Ô∏è Si les deux VMs activent la m√™me MAC en m√™me temps, cela provoque des conflits ARP et peut casser le r√©seau. Seul le MASTER doit activer son WAN.
2. Un hook event CARP procure la possibilit√© de lancer des scripts. J‚Äôai d√©ploy√© ce [script Gist](https://gist.github.com/spali/2da4f23e488219504b2ada12ac59a7dc#file-10-wancarp) dans `/usr/local/etc/rc.syshook.d/carp/10-wan` sur les deux n≈ìuds. Ce script active le WAN uniquement sur le MASTER.
```php
#!/usr/local/bin/php
<?php

require_once("config.inc");
require_once("interfaces.inc");
require_once("util.inc");
require_once("system.inc");

$subsystem = !empty($argv[1]) ? $argv[1] : '';
$type = !empty($argv[2]) ? $argv[2] : '';

if ($type != 'MASTER' && $type != 'BACKUP') {
    log_error("Carp '$type' event unknown from source '{$subsystem}'");
    exit(1);
}

if (!strstr($subsystem, '@')) {
    log_error("Carp '$type' event triggered from wrong source '{$subsystem}'");
    exit(1);
}

$ifkey = 'wan';

if ($type === "MASTER") {
    log_error("enable interface '$ifkey' due CARP event '$type'");
    $config['interfaces'][$ifkey]['enable'] = '1';
    write_config("enable interface '$ifkey' due CARP event '$type'", false);
    interface_configure(false, $ifkey, false, false);
} else {
    log_error("disable interface '$ifkey' due CARP event '$type'");
    unset($config['interfaces'][$ifkey]['enable']);
    write_config("disable interface '$ifkey' due CARP event '$type'", false);
    interface_configure(false, $ifkey, false, false);
}
```

### Tester le Failover

Passons aux tests !

OPNsense propose un _CARP Maintenance Mode_. Avec le master actif, seul lui avait son WAN mont√©. En activant le mode maintenance, les r√¥les basculent : le master devient backup, son WAN est d√©sactiv√© et celui du backup est activ√© :  
![Mode maintenance CARP dans OPNsense](img/opnsense-vm-carp-status.png)

Pendant mes pings vers l‚Äôext√©rieur, aucune perte de paquets au moment du basculement.

Ensuite, j‚Äôai simul√© un crash en √©teignant le master. Le backup a pris le relais de fa√ßon transparente, seulement un paquet perdu, et gr√¢ce √† la synchro des √©tats, m√™me ma session SSH est rest√©e ouverte. üéâ

## Conclusion

Cette preuve de concept d√©montre qu‚Äôil est possible de faire tourner **OPNsense en haute dispo sous Proxmox VE**, m√™me avec une seule IP WAN. Les briques n√©cessaires :
- Segmentation VLAN
- R√©seau d√©di√© pfSync
- IP virtuelle partag√©e (CARP)
- Script pour g√©rer l‚Äôinterface WAN

Le r√©sultat est √† la hauteur : failover transparent, synchro des √©tats, et connexions actives qui survivent √† un crash.  Le point le plus d√©licat reste la gestion du bail WAN, mais le hook CARP r√®gle ce probl√®me.

üöÄ Prochaine √©tape : pr√©parer un nouveau cluster OPNsense HA sur Proxmox en vue de remplacer compl√®tement ma box physique actuel. Restez √† l'√©coute !